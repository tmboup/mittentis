CREATE TABLE mesures( 
    id INTEGER primary key autoincrement, 
    sensor_id INTEGER, data_type INTEGER, 
    value INTEGER, sent INTEGER default 0, 
    received INTEGER default 0, 
    unix_ts DATETIME DEFAULT CURRENT_TIMESTAMP
    
    )

var sql = "create table IF NOT EXISTS mesures( id INTEGER primary key autoincrement, 
                                                sensor_id INTEGER, data_type INTEGER, 
                                                value INTEGER, sent INTEGER default 0, 
                                                received INTEGER default 0, 
                                                unix_ts DATETIME DEFAULT CURRENT_TIMESTAMP
                                                )" ;




import os
import psycopg2
from psycopg2.extras import RealDictCursor

def get_latest_mesures():
    conn = psycopg2.connect(os.getenv("DB_LOCAL_URL"))
    cur = conn.cursor(cursor_factory=RealDictCursor)
    cur.execute(""" SELECT id, created_at, date, parameter, unit, updated_at, value, sensor_id FROM mesure WHERE sent IS FALSE OR sent IS NULL """)
    rows = cur.fetchall()
    
    # Optionnel : marquer comme envoyÃ©es ici ou plus tard aprÃ¨s succÃ¨s
    
    conn.commit()
    cur.close()
    conn.close()
    return rows


####################################################################################################################################################################################
6`

* exÃ©cute ton programme toutes les 4 heures,
* redÃ©marre automatiquement si le serveur redÃ©marre,
* gÃ¨re les logs et les erreurs proprement.

La **meilleure pratique sous Ubuntu** nâ€™est pas `cron` (trop limitÃ© en redÃ©marrage et monitoring), mais **systemd timers**. Câ€™est moderne, fiable, relance aprÃ¨s reboot et gÃ¨re les logs avec `journalctl`.

---

## ğŸš€ Ã‰tapes pour dÃ©ployer ton script avec systemd timer

### 1. CrÃ©e un script exÃ©cutable

Disons que ton code est dans `sync_data.py`.

ğŸ‘‰ CrÃ©e un wrapper shell `/usr/local/bin/sync_data.sh` :

```bash
#!/bin/bash
set -euo pipefail

# Activer lâ€™environnement Python si besoin
# source /home/tonuser/venv/bin/activate

# ExÃ©cuter ton script et capturer les logs
python3 /home/tonuser/projet/sync_data.py >> /var/log/sync_data.log 2>&1
```

Puis rends-le exÃ©cutable :

```bash
chmod +x /usr/local/bin/sync_data.sh
```

---

### 2. CrÃ©e un service systemd

Fichier : `/etc/systemd/system/sync_data.service`

```ini
[Unit]
Description=Synchronisation des mesures locales vers la base distante
After=network.target

[Service]
Type=oneshot
ExecStart=/usr/local/bin/sync_data.sh
# Relance automatique si crash
Restart=on-failure
RestartSec=10
```

---

### 3. CrÃ©e un timer systemd

Fichier : `/etc/systemd/system/sync_data.timer`

```ini
[Unit]
Description=Timer pour sync_data toutes les 4 heures

[Timer]
# Lancer toutes les 4 heures
OnCalendar=*:0/4
Persistent=true

[Install]
WantedBy=timers.target
```

> âœ… `Persistent=true` â†’ si la machine Ã©tait Ã©teinte pendant une exÃ©cution, systemd exÃ©cute le job dÃ¨s le redÃ©marrage pour rattraper. (Ce que `cron` ne fait pas).

---

### 4. Active et dÃ©marre

```bash
# Recharger systemd
sudo systemctl daemon-reload

# Activer le timer
sudo systemctl enable --now sync_data.timer

# VÃ©rifier
systemctl list-timers | grep sync_data
```

---

### 5. Logs et suivi

Voir les logs en temps rÃ©el :

```bash
journalctl -u sync_data.service -f
```

Ou lire les logs enregistrÃ©s :

```bash
cat /var/log/sync_data.log
```

---

## âœ… Avantages de cette approche

* **TolÃ©rance aux fautes** : si le script crash â†’ relance.
* **Persistance** : si la machine redÃ©marre â†’ le job continue automatiquement.
* **FiabilitÃ©** : `systemd` est plus robuste que `cron`.
* **Debug facile** : logs centralisÃ©s (`journalctl`).

---

ğŸ‘‰ Veux-tu que je tâ€™Ã©crive aussi une **version "safe" de ton `sync_data.py`** (avec gestion des exceptions, logs robustes, retry si le serveur distant est down), pour que le dÃ©ploiement soit vraiment **premium++** ?
